{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing Dataset\n",
    "df = pd.read_csv('50_Startups.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State\n",
       "0  165349.20       136897.80        471784.10    New York\n",
       "1  162597.70       151377.59        443898.53  California\n",
       "2  153441.51       101145.55        407934.54     Florida\n",
       "3  144372.41       118671.85        383199.62    New York\n",
       "4  142107.34        91391.77        366168.42     Florida"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    192261.83\n",
       "1    191792.06\n",
       "2    191050.39\n",
       "3    182901.99\n",
       "4    166187.94\n",
       "Name: Profit, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python64_new\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "c:\\python64_new\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Encoding Categorical Features\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "X.iloc[:,3] = label_enc.fit_transform(X.iloc[:,3])\n",
    "\n",
    "hot_enc = OneHotEncoder(categorical_features=[3])\n",
    "X = hot_enc.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Avoiding Dummy Variable Trap by removing one dummy variable\n",
    "X = X[:, 1:]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "\n",
    "#Firring training set to our model\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "#Prediting\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([111616.64259409, 132709.39466326, 140155.11033758,  76099.20398151,\n",
       "       186329.94240345, 112822.19807268,  63002.00394814,  99107.10428088,\n",
       "       119287.75473354, 175522.83864711, 101000.69861468,  85772.99293243,\n",
       "       117713.76481485,  90230.8808521 , 133375.04389421, 167530.54765796,\n",
       "       158013.54602026])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model improvement usinf Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTANT :\n",
    "\n",
    "Now, as we know in multiple linear regression,\n",
    "\n",
    "```y = b0+b1X1+b2X2+b3X3+….+bnXn```\n",
    "\n",
    "we can also represent it as\n",
    "\n",
    "```y = b0X0+b1X1+b2X2+b3X3+….+bnXn where X0 = 1```\n",
    "\n",
    "So we can add one column with all values as 1 to represent ```b0X0```.\n",
    "\n",
    "This is done because statsmodels library requires it to be done for constants.\n",
    "\n",
    "#### Signinficance Level = 0.05 (random choice of 5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.6534920e+05,\n",
       "        1.3689780e+05, 4.7178410e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.6259770e+05,\n",
       "        1.5137759e+05, 4.4389853e+05]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Appending new column with 1's to X matrix\n",
    "X = np.append(arr=np.ones((X.shape[0],1)).astype(int), values=X , axis=1)\n",
    "\n",
    "X[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#According to backward elimination for multiple linear regression algorithm, let us fit all variables in our model\n",
    "X_opt = X[:,[0,1,2,3,4,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Profit</td>      <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   169.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 22 Jan 2019</td> <th>  Prob (F-statistic):</th> <td>1.34e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:38:13</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    44</td>      <th>  BIC:               </th> <td>   1074.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.013e+04</td> <td> 6884.820</td> <td>    7.281</td> <td> 0.000</td> <td> 3.62e+04</td> <td>  6.4e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  198.7888</td> <td> 3371.007</td> <td>    0.059</td> <td> 0.953</td> <td>-6595.030</td> <td> 6992.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>  -41.8870</td> <td> 3256.039</td> <td>   -0.013</td> <td> 0.990</td> <td>-6604.003</td> <td> 6520.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.369</td> <td> 0.000</td> <td>    0.712</td> <td>    0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.517</td> <td> 0.608</td> <td>   -0.132</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.574</td> <td> 0.123</td> <td>   -0.008</td> <td>    0.062</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.782</td> <th>  Durbin-Watson:     </th> <td>   1.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.41e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.572</td> <th>  Cond. No.          </th> <td>1.45e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.45e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Profit   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     169.9\n",
       "Date:                Tue, 22 Jan 2019   Prob (F-statistic):           1.34e-27\n",
       "Time:                        08:38:13   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1063.\n",
       "Df Residuals:                      44   BIC:                             1074.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.013e+04   6884.820      7.281      0.000    3.62e+04     6.4e+04\n",
       "x1           198.7888   3371.007      0.059      0.953   -6595.030    6992.607\n",
       "x2           -41.8870   3256.039     -0.013      0.990   -6604.003    6520.229\n",
       "x3             0.8060      0.046     17.369      0.000       0.712       0.900\n",
       "x4            -0.0270      0.052     -0.517      0.608      -0.132       0.078\n",
       "x5             0.0270      0.017      1.574      0.123      -0.008       0.062\n",
       "==============================================================================\n",
       "Omnibus:                       14.782   Durbin-Watson:                   1.283\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.266\n",
       "Skew:                          -0.948   Prob(JB):                     2.41e-05\n",
       "Kurtosis:                       5.572   Cond. No.                     1.45e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.45e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Profit</td>      <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   217.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 22 Jan 2019</td> <th>  Prob (F-statistic):</th> <td>8.49e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:42:14</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1061.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   1070.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.011e+04</td> <td> 6647.870</td> <td>    7.537</td> <td> 0.000</td> <td> 3.67e+04</td> <td> 6.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  220.1585</td> <td> 2900.536</td> <td>    0.076</td> <td> 0.940</td> <td>-5621.821</td> <td> 6062.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.606</td> <td> 0.000</td> <td>    0.714</td> <td>    0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.523</td> <td> 0.604</td> <td>   -0.131</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.592</td> <td> 0.118</td> <td>   -0.007</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.758</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.53e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.563</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Profit   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.946\n",
       "Method:                 Least Squares   F-statistic:                     217.2\n",
       "Date:                Tue, 22 Jan 2019   Prob (F-statistic):           8.49e-29\n",
       "Time:                        08:42:14   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1061.\n",
       "Df Residuals:                      45   BIC:                             1070.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.011e+04   6647.870      7.537      0.000    3.67e+04    6.35e+04\n",
       "x1           220.1585   2900.536      0.076      0.940   -5621.821    6062.138\n",
       "x2             0.8060      0.046     17.606      0.000       0.714       0.898\n",
       "x3            -0.0270      0.052     -0.523      0.604      -0.131       0.077\n",
       "x4             0.0270      0.017      1.592      0.118      -0.007       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.758   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.172\n",
       "Skew:                          -0.948   Prob(JB):                     2.53e-05\n",
       "Kurtosis:                       5.563   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove 2nd column i.e. x2 because its p-value is maximum i.e. 0.990\n",
    "# Now fit ehe model again \n",
    "X_opt = X[:,[0,1,3,4,5]]\n",
    "regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Profit</td>      <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   296.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 22 Jan 2019</td> <th>  Prob (F-statistic):</th> <td>4.53e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:42:41</td>     <th>  Log-Likelihood:    </th> <td> -525.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    46</td>      <th>  BIC:               </th> <td>   1066.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.012e+04</td> <td> 6572.353</td> <td>    7.626</td> <td> 0.000</td> <td> 3.69e+04</td> <td> 6.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8057</td> <td>    0.045</td> <td>   17.846</td> <td> 0.000</td> <td>    0.715</td> <td>    0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0268</td> <td>    0.051</td> <td>   -0.526</td> <td> 0.602</td> <td>   -0.130</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0272</td> <td>    0.016</td> <td>    1.655</td> <td> 0.105</td> <td>   -0.006</td> <td>    0.060</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.838</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.949</td> <th>  Prob(JB):          </th> <td>2.21e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.586</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Profit   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     296.0\n",
       "Date:                Tue, 22 Jan 2019   Prob (F-statistic):           4.53e-30\n",
       "Time:                        08:42:41   Log-Likelihood:                -525.39\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      46   BIC:                             1066.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.012e+04   6572.353      7.626      0.000    3.69e+04    6.34e+04\n",
       "x1             0.8057      0.045     17.846      0.000       0.715       0.897\n",
       "x2            -0.0268      0.051     -0.526      0.602      -0.130       0.076\n",
       "x3             0.0272      0.016      1.655      0.105      -0.006       0.060\n",
       "==============================================================================\n",
       "Omnibus:                       14.838   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.442\n",
       "Skew:                          -0.949   Prob(JB):                     2.21e-05\n",
       "Kurtosis:                       5.586   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove 1st column i.e. x1 because its p-value is maximum i.e. 0.940\n",
    "# Now fit ehe model again \n",
    "X_opt = X[:,[0,3,4,5]]\n",
    "regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Profit</td>      <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   450.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 22 Jan 2019</td> <th>  Prob (F-statistic):</th> <td>2.16e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:43:58</td>     <th>  Log-Likelihood:    </th> <td> -525.54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1057.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.698e+04</td> <td> 2689.933</td> <td>   17.464</td> <td> 0.000</td> <td> 4.16e+04</td> <td> 5.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.7966</td> <td>    0.041</td> <td>   19.266</td> <td> 0.000</td> <td>    0.713</td> <td>    0.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0299</td> <td>    0.016</td> <td>    1.927</td> <td> 0.060</td> <td>   -0.001</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.677</td> <th>  Durbin-Watson:     </th> <td>   1.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.939</td> <th>  Prob(JB):          </th> <td>2.54e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.575</td> <th>  Cond. No.          </th> <td>5.32e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.32e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Profit   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     450.8\n",
       "Date:                Tue, 22 Jan 2019   Prob (F-statistic):           2.16e-31\n",
       "Time:                        08:43:58   Log-Likelihood:                -525.54\n",
       "No. Observations:                  50   AIC:                             1057.\n",
       "Df Residuals:                      47   BIC:                             1063.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.698e+04   2689.933     17.464      0.000    4.16e+04    5.24e+04\n",
       "x1             0.7966      0.041     19.266      0.000       0.713       0.880\n",
       "x2             0.0299      0.016      1.927      0.060      -0.001       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.677   Durbin-Watson:                   1.257\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.161\n",
       "Skew:                          -0.939   Prob(JB):                     2.54e-05\n",
       "Kurtosis:                       5.575   Cond. No.                     5.32e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.32e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove 3rd index i.e. x2 because its p-value is maximum i.e. 0.602\n",
    "# Now fit ehe model again \n",
    "X_opt = X[:,[0,3,5]]\n",
    "regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Profit</td>      <th>  R-squared:         </th> <td>   0.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   849.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 22 Jan 2019</td> <th>  Prob (F-statistic):</th> <td>3.50e-32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:44:33</td>     <th>  Log-Likelihood:    </th> <td> -527.44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.903e+04</td> <td> 2537.897</td> <td>   19.320</td> <td> 0.000</td> <td> 4.39e+04</td> <td> 5.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8543</td> <td>    0.029</td> <td>   29.151</td> <td> 0.000</td> <td>    0.795</td> <td>    0.913</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13.727</td> <th>  Durbin-Watson:     </th> <td>   1.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  18.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.911</td> <th>  Prob(JB):          </th> <td>9.44e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.361</td> <th>  Cond. No.          </th> <td>1.65e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.65e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Profit   R-squared:                       0.947\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     849.8\n",
       "Date:                Tue, 22 Jan 2019   Prob (F-statistic):           3.50e-32\n",
       "Time:                        08:44:33   Log-Likelihood:                -527.44\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      48   BIC:                             1063.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.903e+04   2537.897     19.320      0.000    4.39e+04    5.41e+04\n",
       "x1             0.8543      0.029     29.151      0.000       0.795       0.913\n",
       "==============================================================================\n",
       "Omnibus:                       13.727   Durbin-Watson:                   1.116\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               18.536\n",
       "Skew:                          -0.911   Prob(JB):                     9.44e-05\n",
       "Kurtosis:                       5.361   Cond. No.                     1.65e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.65e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove last i.e. x2 because its p-value is maximum i.e. 0.06\n",
    "# Now fit ehe model again \n",
    "X_opt = X[:,[0,3]]\n",
    "regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000000e+00, 1.653492e+05],\n",
       "       [1.000000e+00, 1.625977e+05]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have obtained the optimal columns needed for prediction, we can use the current state of ```X_opt``` to train LinearRigression model and predict the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_opt_train, X_opt_test, y_opt_train, y_opt_test = train_test_split(X_opt, y, test_size = 1/3, random_state = 0)\n",
    "\n",
    "regressor_opt = LinearRegression()\n",
    "regressor_opt.fit(X_opt_train, y_opt_train)\n",
    " \n",
    "y_opt_pred = regressor_opt.predict(X_opt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([104951.99132775, 135168.59853169, 136251.84402288,  71647.28960668,\n",
       "       181225.68979566, 110237.71821498,  64958.76015748, 100662.0731542 ,\n",
       "       111884.65075337, 171333.26315773,  95737.37863888,  87463.32662999,\n",
       "       113049.23217285,  87822.96252712, 127380.80777111, 161026.22315596,\n",
       "       151988.50891056])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicted values\n",
    "y_opt_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Backward Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Elimination with p-values only :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "def backwardElimination(x, sl):\n",
    "    numVars = len(x[0])\n",
    "    for i in range(0, numVars):\n",
    "        regressor_OLS = sm.OLS(y, x).fit()\n",
    "        maxVar = max(regressor_OLS.pvalues)\n",
    "        if maxVar > sl:\n",
    "            for j in range(0, numVars - i):\n",
    "                if (regressor_OLS.pvalues[j] == maxVar):\n",
    "                    x = np.delete(x, j, 1)\n",
    "    regressor_OLS.summary()\n",
    "    return x\n",
    " \n",
    "SL = 0.05\n",
    "X_opt = X[:, [0, 1, 2, 3, 4, 5]]\n",
    "X_Modeled = backwardElimination(X_opt, SL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000000e+00, 1.653492e+05],\n",
       "       [1.000000e+00, 1.625977e+05]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Modeled[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_opt_train, X_opt_test, y_opt_train, y_opt_test = train_test_split(X_Modeled, y, test_size = 1/3, random_state = 0)\n",
    "\n",
    "regressor_opt = LinearRegression()\n",
    "regressor_opt.fit(X_opt_train, y_opt_train)\n",
    " \n",
    "y_opt_pred_p_values = regressor_opt.predict(X_opt_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In above code we have performed below steps:\n",
    "    1. Deciede a Signinficance Level value (0.05 in this case)\n",
    "    2. For a matrix ```X_opt``` from X. Note that X already has one column of ones appended int eh beginning\n",
    "    3. Fit OLS with y and x and find max of all p values. Repeat this 'n' times, where n = no. of features\n",
    "    4. Iterate over all pvalues and remove the column from x\n",
    "    5. Return optimized variable x\n",
    "    \n",
    "Now ```X_Modeled``` can be used to train LinearRigression model and predict the output as shown at the end of Manual Backward Elimination steps earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Elimination with p-values and Adjusted R Squared :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Profit   R-squared:                       0.950\n",
      "Model:                            OLS   Adj. R-squared:                  0.948\n",
      "Method:                 Least Squares   F-statistic:                     450.8\n",
      "Date:                Tue, 22 Jan 2019   Prob (F-statistic):           2.16e-31\n",
      "Time:                        09:05:25   Log-Likelihood:                -525.54\n",
      "No. Observations:                  50   AIC:                             1057.\n",
      "Df Residuals:                      47   BIC:                             1063.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       4.698e+04   2689.933     17.464      0.000    4.16e+04    5.24e+04\n",
      "x1             0.7966      0.041     19.266      0.000       0.713       0.880\n",
      "x2             0.0299      0.016      1.927      0.060      -0.001       0.061\n",
      "==============================================================================\n",
      "Omnibus:                       14.677   Durbin-Watson:                   1.257\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.161\n",
      "Skew:                          -0.939   Prob(JB):                     2.54e-05\n",
      "Kurtosis:                       5.575   Cond. No.                     5.32e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.32e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "def backwardElimination(x, SL):\n",
    "    numVars = len(x[0])\n",
    "    temp = np.zeros((50,6)).astype(int)\n",
    "    for i in range(0, numVars):\n",
    "        regressor_OLS = sm.OLS(y, x).fit()\n",
    "        maxVar = max(regressor_OLS.pvalues)\n",
    "        adjR_before = regressor_OLS.rsquared_adj\n",
    "        if maxVar > SL:\n",
    "            for j in range(0, numVars - i):\n",
    "                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
    "                    temp[:,j] = x[:, j]\n",
    "                    x = np.delete(x, j, 1)\n",
    "                    tmp_regressor = sm.OLS(y, x).fit()\n",
    "                    adjR_after = tmp_regressor.rsquared_adj\n",
    "                    if (adjR_before >= adjR_after):\n",
    "                        x_rollback = np.hstack((x, temp[:,[0,j]]))\n",
    "                        x_rollback = np.delete(x_rollback, j, 1)\n",
    "                        print (regressor_OLS.summary())\n",
    "                        return x_rollback\n",
    "                    else:\n",
    "                        continue\n",
    "    regressor_OLS.summary()\n",
    "    return x\n",
    " \n",
    "SL = 0.05\n",
    "X_opt = X[:, [0, 1, 2, 3, 4, 5]]\n",
    "X_Modeled = backwardElimination(X_opt, SL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_opt_train, X_opt_test, y_opt_train, y_opt_test = train_test_split(X_Modeled, y, test_size = 1/3, random_state = 0)\n",
    "\n",
    "regressor_opt = LinearRegression()\n",
    "regressor_opt.fit(X_opt_train, y_opt_train)\n",
    " \n",
    "y_opt_pred = regressor_opt.predict(X_opt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103066.94016556, 134980.76805549, 135442.07243882,  73055.75850032,\n",
       "       182480.813546  , 114370.96305097,  67338.78860247,  98232.55355352,\n",
       "       114571.22328457, 172068.26838631,  97021.46443825,  89009.05519005,\n",
       "       111096.4857056 ,  89489.10999604, 128889.89883033, 161252.35482709,\n",
       "       150951.29617416])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_opt_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Profit</th>\n",
       "      <th>Default Prediction</th>\n",
       "      <th>Predicted With P Only</th>\n",
       "      <th>With P and Adjusted R Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103282.38</td>\n",
       "      <td>111616.642594</td>\n",
       "      <td>104951.991328</td>\n",
       "      <td>103066.940166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144259.40</td>\n",
       "      <td>132709.394663</td>\n",
       "      <td>135168.598532</td>\n",
       "      <td>134980.768055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146121.95</td>\n",
       "      <td>140155.110338</td>\n",
       "      <td>136251.844023</td>\n",
       "      <td>135442.072439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77798.83</td>\n",
       "      <td>76099.203982</td>\n",
       "      <td>71647.289607</td>\n",
       "      <td>73055.758500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>191050.39</td>\n",
       "      <td>186329.942403</td>\n",
       "      <td>181225.689796</td>\n",
       "      <td>182480.813546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>105008.31</td>\n",
       "      <td>112822.198073</td>\n",
       "      <td>110237.718215</td>\n",
       "      <td>114370.963051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>81229.06</td>\n",
       "      <td>63002.003948</td>\n",
       "      <td>64958.760157</td>\n",
       "      <td>67338.788602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>97483.56</td>\n",
       "      <td>99107.104281</td>\n",
       "      <td>100662.073154</td>\n",
       "      <td>98232.553554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>110352.25</td>\n",
       "      <td>119287.754734</td>\n",
       "      <td>111884.650753</td>\n",
       "      <td>114571.223285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>166187.94</td>\n",
       "      <td>175522.838647</td>\n",
       "      <td>171333.263158</td>\n",
       "      <td>172068.268386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>96778.92</td>\n",
       "      <td>101000.698615</td>\n",
       "      <td>95737.378639</td>\n",
       "      <td>97021.464438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>96479.51</td>\n",
       "      <td>85772.992932</td>\n",
       "      <td>87463.326630</td>\n",
       "      <td>89009.055190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>105733.54</td>\n",
       "      <td>117713.764815</td>\n",
       "      <td>113049.232173</td>\n",
       "      <td>111096.485706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>96712.80</td>\n",
       "      <td>90230.880852</td>\n",
       "      <td>87822.962527</td>\n",
       "      <td>89489.109996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>124266.90</td>\n",
       "      <td>133375.043894</td>\n",
       "      <td>127380.807771</td>\n",
       "      <td>128889.898830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>155752.60</td>\n",
       "      <td>167530.547658</td>\n",
       "      <td>161026.223156</td>\n",
       "      <td>161252.354827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>132602.65</td>\n",
       "      <td>158013.546020</td>\n",
       "      <td>151988.508911</td>\n",
       "      <td>150951.296174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual Profit  Default Prediction  Predicted With P Only  \\\n",
       "0       103282.38       111616.642594          104951.991328   \n",
       "1       144259.40       132709.394663          135168.598532   \n",
       "2       146121.95       140155.110338          136251.844023   \n",
       "3        77798.83        76099.203982           71647.289607   \n",
       "4       191050.39       186329.942403          181225.689796   \n",
       "5       105008.31       112822.198073          110237.718215   \n",
       "6        81229.06        63002.003948           64958.760157   \n",
       "7        97483.56        99107.104281          100662.073154   \n",
       "8       110352.25       119287.754734          111884.650753   \n",
       "9       166187.94       175522.838647          171333.263158   \n",
       "10       96778.92       101000.698615           95737.378639   \n",
       "11       96479.51        85772.992932           87463.326630   \n",
       "12      105733.54       117713.764815          113049.232173   \n",
       "13       96712.80        90230.880852           87822.962527   \n",
       "14      124266.90       133375.043894          127380.807771   \n",
       "15      155752.60       167530.547658          161026.223156   \n",
       "16      132602.65       158013.546020          151988.508911   \n",
       "\n",
       "    With P and Adjusted R Squared  \n",
       "0                   103066.940166  \n",
       "1                   134980.768055  \n",
       "2                   135442.072439  \n",
       "3                    73055.758500  \n",
       "4                   182480.813546  \n",
       "5                   114370.963051  \n",
       "6                    67338.788602  \n",
       "7                    98232.553554  \n",
       "8                   114571.223285  \n",
       "9                   172068.268386  \n",
       "10                   97021.464438  \n",
       "11                   89009.055190  \n",
       "12                  111096.485706  \n",
       "13                   89489.109996  \n",
       "14                  128889.898830  \n",
       "15                  161252.354827  \n",
       "16                  150951.296174  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combining Actual Test and Predicted values\n",
    "matrix = np.array((y_opt_test.values, y_pred, y_opt_pred_p_values, y_opt_pred))\n",
    "matrix = matrix.T\n",
    "\n",
    "pd.DataFrame(matrix, columns=['Actual Profit', 'Default Prediction', 'Predicted With P Only', 'With P and Adjusted R Squared'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It is clear from above output that Price predicted improves significantly after the model selection is optimized after Backward Elimination with P and Adjusted R Squared."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
